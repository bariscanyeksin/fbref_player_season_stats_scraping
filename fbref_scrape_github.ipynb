{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Season Stats for Players from FBREF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! -> URL: https://fbref.com/en/comps/Big5/stats/players/Big-5-European-Leagues-Stats\n",
      "Done! -> URL: https://fbref.com/en/comps/Big5/shooting/players/Big-5-European-Leagues-Stats\n",
      "Done! -> URL: https://fbref.com/en/comps/Big5/passing/players/Big-5-European-Leagues-Stats\n",
      "Done! -> URL: https://fbref.com/en/comps/Big5/passing_types/players/Big-5-European-Leagues-Stats\n",
      "Done! -> URL: https://fbref.com/en/comps/Big5/gca/players/Big-5-European-Leagues-Stats\n",
      "Done! -> URL: https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats\n",
      "Done! -> URL: https://fbref.com/en/comps/Big5/possession/players/Big-5-European-Leagues-Stats\n",
      "Done! -> URL: https://fbref.com/en/comps/Big5/misc/players/Big-5-European-Leagues-Stats\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Creating the scraping function\n",
    "# This function returns a DataFrame\n",
    "def fetch_data(url):\n",
    "    headers = {\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'accept-language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "        'cache-control': 'max-age=0',\n",
    "        'if-modified-since': 'Thu, 24 Oct 2024 09:58:04 GMT',\n",
    "        'priority': 'u=0, i',\n",
    "        'referer': 'https://fbref.com/en/comps/Big5/Big-5-European-Leagues-Stats',\n",
    "        'sec-ch-ua': '\"Chromium\";v=\"130\", \"Google Chrome\";v=\"130\", \"Not?A_Brand\";v=\"99\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"Windows\"',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'sec-fetch-user': '?1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
    "    }\n",
    "\n",
    "    response = requests.get(\n",
    "        url=url,\n",
    "        headers=headers\n",
    "    )\n",
    "        \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # FBREF tables has a unique structure\n",
    "    # The table has column names with 2 layers\n",
    "    # We should take both of them and combine as a one column name\n",
    "    header_row = []\n",
    "    for th in soup.select(\"thead tr:not(.over_header) th\"):\n",
    "        over_header = th.get('data-over-header', '').replace('-', '_').replace(' ', '_')\n",
    "        current_header = th.get_text(strip=True).replace('-', '_').replace(' ', '_')\n",
    "        if over_header:\n",
    "            new_header = f\"{over_header.replace(' ', '')}_{current_header}\"\n",
    "        else:\n",
    "            new_header = current_header\n",
    "        header_row.append(new_header)\n",
    "\n",
    "    # Fetching data in the rows\n",
    "    rows = []\n",
    "    for row in soup.select(\"tbody tr\"):\n",
    "        cells = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        rows.append(cells)\n",
    "    \n",
    "    # If the header row has an extra entry, removing first item in header_row to align the lengths\n",
    "    if len(header_row) > len(rows[0]):\n",
    "        header_row.pop(0)\n",
    "    \n",
    "    # Now we have data(row) and columns(header_row), so let's convert them to a DataFrame\n",
    "    df = pd.DataFrame(rows, columns=header_row)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    # Editing for 'Nation' and 'Comp' columns\n",
    "    df = extract_uppercase(df)\n",
    "    \n",
    "    # Removing 'Matches' column\n",
    "    df = df.drop(columns=['Matches'])\n",
    "\n",
    "    # Age column is like '23-190', so we are taking just '23' in here\n",
    "    df['Age'] = df['Age'].str.split('-', expand=True)[0]\n",
    "    \n",
    "    print(f\"Done! -> URL: {url}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# This function edits the data in the 'Nation' and 'Comp' columns\n",
    "def extract_uppercase(df):\n",
    "    # 'eng ENG' -> 'ENG'\n",
    "    if 'Nation' in df.columns:\n",
    "        df['Nation'] = df['Nation'].str.extract(r'([A-Z]+)')[0]\n",
    "    \n",
    "    # 'es La Liga' -> 'La Liga'\n",
    "    if 'Comp' in df.columns:\n",
    "        df['Comp'] = df['Comp'].str.extract(r'([A-Z][a-zA-Z\\s]*)')[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Defining FBREF pages as a list we want to scrape\n",
    "urls = [\n",
    "    'https://fbref.com/en/comps/Big5/stats/players/Big-5-European-Leagues-Stats',\n",
    "    'https://fbref.com/en/comps/Big5/shooting/players/Big-5-European-Leagues-Stats',\n",
    "    'https://fbref.com/en/comps/Big5/passing/players/Big-5-European-Leagues-Stats',\n",
    "    'https://fbref.com/en/comps/Big5/passing_types/players/Big-5-European-Leagues-Stats',\n",
    "    'https://fbref.com/en/comps/Big5/gca/players/Big-5-European-Leagues-Stats',\n",
    "    'https://fbref.com/en/comps/Big5/defense/players/Big-5-European-Leagues-Stats',\n",
    "    'https://fbref.com/en/comps/Big5/possession/players/Big-5-European-Leagues-Stats',\n",
    "    'https://fbref.com/en/comps/Big5/misc/players/Big-5-European-Leagues-Stats'\n",
    "]\n",
    "\n",
    "# Extract and merge data from all URLs\n",
    "dfs = []\n",
    "for url in urls:\n",
    "    df = fetch_data(url)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Inserting DataFrames side by side\n",
    "final_df = pd.concat(dfs, axis=1)\n",
    "\n",
    "# Removing duplicating columns\n",
    "final_df = final_df.loc[:,~final_df.columns.duplicated()]\n",
    "\n",
    "# Exporting as csv\n",
    "final_df.to_csv('fbref_player_stats.csv', encoding=\"utf-8-sig\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
